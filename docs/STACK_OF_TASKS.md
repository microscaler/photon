# üóÇÔ∏è Stack of Next Tasks (Organized by Roadmap Phase)

A prioritized and categorized backlog of tasks to drive Photon development across CLI, SaaS, and infrastructure components.

---

## üöß Phase 1 ‚Äì CLI MLP

- [ ] Create `photon new` scaffold generator
- [ ] Build `photon generate model` command
- [ ] Design and prototype `photon openapi navigate`
- [ ] Implement `photon ui generate form` (OpenAPI ‚Üí SolidJS)
- [ ] Add `photon build` command (backend + frontend)

---

## üß† Phase 2 ‚Äì AI Integration

### üì¶ Micro LLM Planning
- [ ] Design prompt templates for CLI/route/schema modes
- [x] Implement OpenAPI prompt generator to create instruction-tuning data from scraped specs ‚úÖ `PHOTON_OPENAPI_PROMPT_GENERATOR.md` committed
- [ ] Write OpenAPI scraping strategy to extract real-world training examples
- [ ] Implement OpenAPI scraper to collect and normalize public specs
- [ ] Define LLM training roadmap for OpenAPI-focused model
- [x] Document local setup prerequisites (Docker, Python, CUDA, etc) ‚úÖ `PHOTON_MICRO_LLM_PREREQUISITES.md` committed
- [ ] Evaluate local vs cloud (Hugging Face, Colab, AWS) training paths
- [x] Plan dataset structure: instruction-response pairs, OpenAPI schema coverage ‚úÖ `Dataset-Design-for-the-Photon-micro-LLM.md` committed
- [x] Design validation/evaluation strategy (schema compliance, test harnesses) ‚úÖ `PHOTON_MICRO_LLM_VALIDATION_STRATEGY.md` committed
- [x] Commit `PHOTON_MICRO_LLM_BOOTSTRAPPING.md` for GPT-based dataset generation ‚úÖ committed
- [x] Commit `PHOTON_MICRO_LLM_SELECTION.md` with rationale for best model choice ‚úÖ `Mistral 7B` selected
- [x] Commit `PHOTON_MICRO_LLM_TRAINING_PIPELINE.md` for fine-tuning a local model ‚úÖ committed
- [x] Commit `PHOTON_MICRO_LLM_SIZING.md` with quantized model size breakdowns ‚úÖ committed

### üîå AI Backend & Model Strategy
- [x] Finalize `PHOTON_AI_BACKENDS.md` for supported AI providers and CLI integration ‚úÖ committed

### üîê Future AI Capabilities
- [x] Design token budgeting strategy for OpenAPI context embedding ‚úÖ `PHOTON_AI_SYSTEM_DESIGN.md` committed
- [x] Support streaming AI responses in `photon ai` CLI ‚úÖ `PHOTON_AI_SYSTEM_DESIGN.md` committed
- [x] Add secure prompt logging system with opt-in and redaction ‚úÖ `PHOTON_AI_SYSTEM_DESIGN.md` committed
- [ ] Design prompt versioning and replay for reproducible AI output

- [x] Finalize AI prompt schema: input structure, context, and format ‚úÖ `PHOTON_AI_PROMPT_SCHEMA.md` committed
- [ ] Define response model: OpenAPI, code snippets, CLI decisions
- [x] Add AI backend support to Photon CLI (`photon ai <prompt>`) ‚úÖ `PHOTON_AI_COMMAND_EXECUTION.md` committed
- [ ] Define `ai` commands:
    - `suggest-path`
    - `generate-model`
    - `refactor-schema`
    - `doc-route`
- [ ] Plan SaaS server LLM integration:
    - Provider abstraction: OpenAI, Claude, local
    - Token limits, streaming, retry
- [ ] Define AI system messages and prompt templates
- [ ] Implement prompt history + audit trail (`logs/prompts.json`)
- [ ] Write fallback strategy for missing context or malformed response
